{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda38a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dee53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d8049cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value function:\n",
      "State 0: 0.45\n",
      "State 1: 0.58\n",
      "State 2: 0.47\n",
      "State 3: 0.72\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#First visit\n",
    "import numpy as np\n",
    "\n",
    "# Define the simple environment\n",
    "class Environment:\n",
    "    def __init__(self):\n",
    "        self.num_states = 5\n",
    "        self.num_actions = 2\n",
    "        self.transitions = {\n",
    "            0: [1, 2],\n",
    "            1: [0, 3],\n",
    "            2: [0, 3],\n",
    "            3: [1, 4],\n",
    "            4: [2, 4]\n",
    "        }\n",
    "        self.rewards = {0: 0, 1: 0, 2: 0, 3: 0, 4: 1}\n",
    "\n",
    "    def step(self, state, action):\n",
    "        next_state = np.random.choice(self.transitions[state])\n",
    "        reward = self.rewards[next_state]\n",
    "        return next_state, reward\n",
    "\n",
    "\n",
    "# First-visit Monte Carlo algorithm\n",
    "def first_visit_monte_carlo(env, num_episodes, gamma=0.9):\n",
    "    returns_sum = defaultdict(float)\n",
    "    returns_count = defaultdict(float)\n",
    "    V = defaultdict(float)\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        episode = []\n",
    "        state = 0  # starting state\n",
    "        while True:\n",
    "            action = np.random.randint(env.num_actions)  # choose a random action\n",
    "            next_state, reward = env.step(state, action)\n",
    "            episode.append((state, reward))\n",
    "            if next_state == 4:  # terminal state\n",
    "                break\n",
    "            state = next_state\n",
    "\n",
    "        states_in_episode = set([x[0] for x in episode])\n",
    "        for state in states_in_episode:\n",
    "            first_occurrence_idx = next(i for i, x in enumerate(episode) if x[0] == state)\n",
    "            G = sum([x[1] * (gamma ** i) for i, x in enumerate(episode[first_occurrence_idx:])])\n",
    "            returns_sum[state] += G\n",
    "            returns_count[state] += 1\n",
    "            V[state] = returns_sum[state] / returns_count[state]\n",
    "\n",
    "    return V\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from collections import defaultdict\n",
    "\n",
    "    env = Environment()\n",
    "    num_episodes = 10\n",
    "    V = first_visit_monte_carlo(env, num_episodes)\n",
    "    print(\"Value function:\")\n",
    "    for state, value in V.items():\n",
    "        print(f\"State {state}: {value:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3296df3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value function:\n",
      "State 3: 0.76\n",
      "State 1: 0.57\n",
      "State 0: 0.51\n",
      "State 2: 0.56\n"
     ]
    }
   ],
   "source": [
    "#Every visit\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define the simple environment\n",
    "class Environment:\n",
    "    def __init__(self):\n",
    "        self.num_states = 5\n",
    "        self.num_actions = 2\n",
    "        self.transitions = {\n",
    "            0: [1, 2],\n",
    "            1: [0, 3],\n",
    "            2: [0, 3],\n",
    "            3: [1, 4],\n",
    "            4: [2, 4]\n",
    "        }\n",
    "        self.rewards = {0: 0, 1: 0, 2: 0, 3: 0, 4: 1}\n",
    "\n",
    "    def step(self, state, action):\n",
    "        next_state = np.random.choice(self.transitions[state])\n",
    "        reward = self.rewards[next_state]\n",
    "        return next_state, reward\n",
    "\n",
    "# Every-visit Monte Carlo algorithm\n",
    "def every_visit_monte_carlo(env, num_episodes, gamma=0.9):\n",
    "    returns_sum = defaultdict(float)\n",
    "    returns_count = defaultdict(float)\n",
    "    V = defaultdict(float)\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        episode = []\n",
    "        state = 0  # starting state\n",
    "        while True:\n",
    "            action = np.random.randint(env.num_actions)  # choose a random action\n",
    "            next_state, reward = env.step(state, action)\n",
    "            episode.append((state, reward))\n",
    "            if next_state == 4:  # terminal state\n",
    "                break\n",
    "            state = next_state\n",
    "\n",
    "        G = 0\n",
    "        for t in range(len(episode) - 1, -1, -1):\n",
    "            state_t, reward_t = episode[t]\n",
    "            G = gamma * G + reward_t\n",
    "            returns_sum[state_t] += G\n",
    "            returns_count[state_t] += 1\n",
    "            V[state_t] = returns_sum[state_t] / returns_count[state_t]\n",
    "\n",
    "    return V\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    env = Environment()\n",
    "    num_episodes = 1000\n",
    "    V = every_visit_monte_carlo(env, num_episodes)\n",
    "    print(\"Value function:\")\n",
    "    for state, value in V.items():\n",
    "        print(f\"State {state}: {value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e6373c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
